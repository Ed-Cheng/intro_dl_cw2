{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TO-DO\n",
    "- Evaluation (metrics) -> plot of training vs epoch for all, AUC\n",
    "- Ablation study: CV comparing binary vs no binary for MTL\n",
    "\n",
    "Training/implementation methodologies: Need to be more scientific in how we chose\n",
    "- Hyper parameters e.g LR (LR finder), batch_size (quote frozen batch norm)\n",
    "- CV for ablation, fine-tuning, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import backend as K\n",
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from utils.loader import DataLoader\n",
    "from models.effnet_encoder import EffnetEncoder\n",
    "from models.mtl_framework import MTLFramework\n",
    "from utils import tools, config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set configs\n",
    "batch_size = 8\n",
    "batch_size_val = 8\n",
    "num_train, num_val, num_test = config.config['num_train'], config.config['num_val'], config.config['num_test']\n",
    "img_height, img_width, channels = config.config['input_shape']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2210 738 738\n"
     ]
    }
   ],
   "source": [
    "print(num_train, num_val, num_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build our MTL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model():\n",
    "    ### CLEARS OLD MODELS IN CACHE\n",
    "    tf.keras.backend.clear_session()\n",
    "\n",
    "    # Get encoder\n",
    "    base_model_name = 'B0'\n",
    "    encoder = EffnetEncoder(base_model_name, (img_height, img_width, channels)).build_encoder(trainable=True)\n",
    "\n",
    "    # Use our MTL framework to custom build a model\n",
    "    mtl_builder = MTLFramework(encoder, (img_height, img_width, channels))\n",
    "    mtl_builder.add_segmentation_head()\n",
    "    mtl_builder.add_binary_classification_head(base_model_name, trainable=True)\n",
    "    mtl_builder.add_bbox_classification_head(base_model_name, trainable=True)\n",
    "    model = mtl_builder.build_mtl_model()\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator_img(img_ds, masks_ds, label_ds, bbox_ds):\n",
    "    ''' Merges together datasets into a unified generator to pass for training '''\n",
    "    a = img_ds.as_numpy_iterator()\n",
    "    b = masks_ds.as_numpy_iterator()\n",
    "    c = label_ds.as_numpy_iterator()\n",
    "    d = bbox_ds.as_numpy_iterator()\n",
    "    \n",
    "    while True:\n",
    "        X = a.next()\n",
    "        Y1 = b.next()\n",
    "        Y2 = c.next()\n",
    "        Y3 = d.next()\n",
    "        \n",
    "        # Regularisation and shuffling\n",
    "        X, Y1, Y2, Y3 = tools.get_randomised_data([X, Y1, Y2, Y3])\n",
    "        # X, Y1, Y3 = tools.data_augmentation(X, Y1, Y3) # Fix augmentation\n",
    "        \n",
    "        yield X, (Y1, Y2, Y3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator_img_val(img_ds_val, masks_ds_val, label_ds_val, bbox_ds):\n",
    "    ''' Merges together datasets into a unified generator to pass for training '''\n",
    "    a = img_ds_val.as_numpy_iterator()\n",
    "    b = masks_ds_val.as_numpy_iterator()\n",
    "    c = label_ds_val.as_numpy_iterator()\n",
    "    d = bbox_ds.as_numpy_iterator()\n",
    "    \n",
    "    while True:\n",
    "        X = a.next()\n",
    "        Y1 = b.next()\n",
    "        Y2 = c.next()\n",
    "        Y3 = d.next()\n",
    "        \n",
    "        yield X, (Y1, Y2, Y3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Start cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- start cross val 1 --------------------\n",
      "Epoch 1/4\n",
      "276/276 [==============================] - 144s 474ms/step - loss: 2.1330 - segnet_out_loss: 0.4231 - bin_class_out_loss: 0.5948 - bbox_out_loss: 111.5121 - segnet_out_accuracy: 0.8003 - bin_class_out_accuracy: 0.7405 - bbox_out_accuracy: 0.2921 - val_loss: 2.1921 - val_segnet_out_loss: 0.2663 - val_bin_class_out_loss: 0.8189 - val_bbox_out_loss: 110.6950 - val_segnet_out_accuracy: 0.8999 - val_bin_class_out_accuracy: 0.2011 - val_bbox_out_accuracy: 0.4239\n",
      "Epoch 2/4\n",
      "276/276 [==============================] - 130s 473ms/step - loss: 1.4389 - segnet_out_loss: 0.2123 - bin_class_out_loss: 0.1450 - bbox_out_loss: 108.1685 - segnet_out_accuracy: 0.9241 - bin_class_out_accuracy: 0.9583 - bbox_out_accuracy: 0.4715 - val_loss: 2.8203 - val_segnet_out_loss: 0.2234 - val_bin_class_out_loss: 1.5102 - val_bbox_out_loss: 108.6697 - val_segnet_out_accuracy: 0.9043 - val_bin_class_out_accuracy: 0.0516 - val_bbox_out_accuracy: 0.3587\n",
      "Epoch 3/4\n",
      " 39/276 [===>..........................] - ETA: 1:22 - loss: 1.3073 - segnet_out_loss: 0.2235 - bin_class_out_loss: 0.0612 - bbox_out_loss: 102.2665 - segnet_out_accuracy: 0.9131 - bin_class_out_accuracy: 1.0000 - bbox_out_accuracy: 0.5000"
     ]
    }
   ],
   "source": [
    "for cv_iter in range(3):\n",
    "      print(f\"-------------------- start cross val {cv_iter+1} --------------------\")\n",
    "      # CrossVal: 0 = no CV, 1 = training set, 2 = val set\n",
    "      loader1 = DataLoader(batch_size=batch_size, batch_size_val=batch_size_val, CrossVal=1, CV_iteration = cv_iter)\n",
    "      loader2 = DataLoader(batch_size=batch_size, batch_size_val=batch_size_val, CrossVal=2, CV_iteration = cv_iter)\n",
    "\n",
    "      # Train set\n",
    "      img_ds = loader1.get_image_ds().repeat()\n",
    "      masks_ds = loader1.get_mask_ds().repeat()\n",
    "      label_ds = loader1.get_binary_ds().repeat()\n",
    "      bbox_ds = loader1.get_bboxes_ds().repeat()\n",
    "\n",
    "      # Validation set\n",
    "      img_ds_val = loader2.get_image_ds().repeat()\n",
    "      masks_ds_val = loader2.get_mask_ds().repeat()\n",
    "      label_ds_val = loader2.get_binary_ds().repeat()\n",
    "      bbox_ds_val = loader2.get_bboxes_ds().repeat()\n",
    "      \n",
    "      model = build_model()\n",
    "\n",
    "      model.compile(optimizer=keras.optimizers.Adam(1e-4),\n",
    "                  loss={'segnet_out' : tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "                        'bin_class_out' : tf.keras.losses.BinaryCrossentropy(),\n",
    "                        'bbox_out' : tf.keras.losses.MeanAbsoluteError()},\n",
    "                  loss_weights=[1,1,1/100], # Scale MAE to BC range\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "      history = model.fit(generator_img(img_ds, masks_ds, label_ds, bbox_ds), \n",
    "                        validation_data=generator_img_val(img_ds_val, masks_ds_val, label_ds_val, bbox_ds), \n",
    "                        epochs=4, \n",
    "                        steps_per_epoch=num_train//batch_size, \n",
    "                        validation_steps=num_val//batch_size_val)\n",
    "\n",
    "      print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(8,6))\n",
    "#ax.plot(list(range(10)), history.history['segnet_out_accuracy'], 'r-', label='Segmentation - Training Accuracy')\n",
    "ax.plot(list(range(10)), history.history['val_segnet_out_accuracy'], 'r--', label='Segmentation - Validation Accuracy')\n",
    "#ax.plot(list(range(10)), history.history['bin_class_out_accuracy'], 'c-', label='Classification - Training Accuracy')\n",
    "ax.plot(list(range(10)), history.history['val_bin_class_out_accuracy'], 'c--', label='Classification - Validation Accuracy')\n",
    "ax2 = ax.twinx()\n",
    "#ax.plot(list(range(10)), history.history['bbox_out_accuracy'], 'm-', label='Bounding Box - Training Accuracy')\n",
    "ax.plot(list(range(10)), history.history['val_bbox_out_accuracy'], 'm--', label='Bounding Box - Validation Accuracy')\n",
    "ax.legend()\n",
    "ax.set_xlabel('Epochs')\n",
    "ax.set_ylabel('Segmentation/Classification Accuracy')\n",
    "ax2.set_ylabel('Bounding Box Accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('EffishingNetN')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test on test-set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.load_model('EffishingNetN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load test-set\n",
    "img_ds_test = loader.get_image_ds(test_mode=True)\n",
    "masks_ds_test = loader.get_mask_ds(test_mode=True)\n",
    "label_ds_test = loader.get_binary_ds(test_mode=True)\n",
    "bbox_ds_test = loader.get_bboxes_ds(test_mode=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict on test-set\n",
    "seg_pred, bin_pred, bbox_pred = model.predict(img_ds_test, batch_size=10)\n",
    "seg_pred = tf.where(seg_pred >= 0, 1, 0) # Convert to {0,1} binary classes\n",
    "bin_pred = np.round(bin_pred) # Round confidence score\n",
    "\n",
    "bin_acc = np.sum(bin_pred == label_ds_test)/label_ds_test.shape[0]\n",
    "seg_acc = np.sum(seg_pred == masks_ds_test)/(masks_ds_test.shape[0]*(img_height*img_width))\n",
    "iou = np.mean(tools.calculate_iou(bbox_ds_test, bbox_pred))\n",
    "print(f'Binary Acc: {round(bin_acc*100, 3)}%,   Seg Acc: {round(seg_acc*100, 3)}%,    BBox IOU: {round(iou*100, 3)}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_seg_pred(img: np.array, mask_truth: np.array, mask_pred: np.array, bbox_truth: np.array, bbox_pred: np.array):\n",
    "    ''' Show segmentation prediction with bounding box pred '''\n",
    "    fig, (ax1, ax2, ax3, ax4) = plt.subplots(1, 4, figsize=(12,12))\n",
    "    seg_max = tf.where(mask_pred > 0, 1, 0)\n",
    "    box_img_truth = tf.image.draw_bounding_boxes(tf.cast(tf.expand_dims(img, 0), tf.float32), tools.fix_bbox(bbox_truth).reshape([1,1,4])/256, np.array([[255, 0, 0]]))\n",
    "    box_img = tf.image.draw_bounding_boxes(tf.cast(tf.expand_dims(img, 0), tf.float32), tools.fix_bbox(bbox_pred).reshape([1,1,4])/256, np.array([[0, 255, 0]]))\n",
    "    \n",
    "    ax1.imshow(tf.keras.utils.array_to_img(tf.squeeze(box_img_truth)))\n",
    "    ax2.imshow(tf.keras.utils.array_to_img(tf.squeeze(box_img)))\n",
    "    ax3.imshow(tf.keras.utils.array_to_img(mask_truth))\n",
    "    ax4.imshow(tf.keras.utils.array_to_img(seg_max[0]))\n",
    "    ax1.set_title('Truth')\n",
    "    ax2.set_title('Prediction')\n",
    "    ax3.set_title('Truth')\n",
    "    ax4.set_title('Prediction')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualise predictions\n",
    "idx = list(range(img_ds_test.shape[0]))\n",
    "random.shuffle(idx)\n",
    "for i in range(3):\n",
    "    show_seg_pred(img_ds_test[idx[i]], masks_ds_test[idx[i]], seg_pred[idx[i]][tf.newaxis, ...], bbox_ds_test[idx[i]], bbox_pred[idx[i]])"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "13872f827bf2face4951d508a343680c0c465a86f8c76a51d647b255bdadb53b"
  },
  "kernelspec": {
   "display_name": "Python 3.9.9 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
