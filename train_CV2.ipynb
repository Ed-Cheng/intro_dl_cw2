{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intro of this file\n",
    "+ Performs 5 fold cv\n",
    "+ To change the fold numbers, simply change \"CVfolds\" in the section \"Start cross validation\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import backend as K\n",
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from utils.loader import DataLoader\n",
    "from models.effnet_encoder import EffnetEncoder\n",
    "from models.mtl_framework import MTLFramework\n",
    "from utils import tools, config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set configs\n",
    "batch_size = 8\n",
    "batch_size_val = 8\n",
    "num_train, num_val, num_test = config.config['num_train'], config.config['num_val'], config.config['num_test']\n",
    "img_height, img_width, channels = config.config['input_shape']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2210 738 738\n"
     ]
    }
   ],
   "source": [
    "print(num_train, num_val, num_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build our MTL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(img_height, img_width, channels):\n",
    "    ### CLEARS OLD MODELS IN CACHE\n",
    "    tf.keras.backend.clear_session()\n",
    "\n",
    "    # Get encoder\n",
    "    base_model_name = 'B0'\n",
    "    encoder = EffnetEncoder(base_model_name, (img_height, img_width, channels)).build_encoder(trainable=True)\n",
    "\n",
    "    # Use our MTL framework to custom build a model\n",
    "    mtl_builder = MTLFramework(encoder, (img_height, img_width, channels))\n",
    "    mtl_builder.add_segmentation_head()\n",
    "    mtl_builder.add_binary_classification_head(base_model_name, trainable=True)\n",
    "    mtl_builder.add_bbox_classification_head(base_model_name, trainable=True)\n",
    "    model = mtl_builder.build_mtl_model()\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator_img(img_ds, masks_ds, label_ds, bbox_ds):\n",
    "    ''' Merges together datasets into a unified generator to pass for training '''\n",
    "    a = img_ds.as_numpy_iterator()\n",
    "    b = masks_ds.as_numpy_iterator()\n",
    "    c = label_ds.as_numpy_iterator()\n",
    "    d = bbox_ds.as_numpy_iterator()\n",
    "    \n",
    "    while True:\n",
    "        X = a.next()\n",
    "        Y1 = b.next()\n",
    "        Y2 = c.next()\n",
    "        Y3 = d.next()\n",
    "        \n",
    "        # Regularisation and shuffling\n",
    "        X, Y1, Y2, Y3 = tools.get_randomised_data([X, Y1, Y2, Y3])\n",
    "        # X, Y1, Y3 = tools.data_augmentation(X, Y1, Y3) # Fix augmentation\n",
    "        \n",
    "        yield X, (Y1, Y2, Y3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator_img_val(img_ds_val, masks_ds_val, label_ds_val, bbox_ds):\n",
    "    ''' Merges together datasets into a unified generator to pass for training '''\n",
    "    a = img_ds_val.as_numpy_iterator()\n",
    "    b = masks_ds_val.as_numpy_iterator()\n",
    "    c = label_ds_val.as_numpy_iterator()\n",
    "    d = bbox_ds.as_numpy_iterator()\n",
    "    \n",
    "    while True:\n",
    "        X = a.next()\n",
    "        Y1 = b.next()\n",
    "        Y2 = c.next()\n",
    "        Y3 = d.next()\n",
    "        \n",
    "        yield X, (Y1, Y2, Y3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Start cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- start cross val 1/3 --------------------\n",
      "Epoch 1/3\n",
      "184/184 [==============================] - 112s 567ms/step - loss: 1.8210 - segnet_out_loss: 0.4778 - bin_class_out_loss: 0.2415 - bbox_out_loss: 110.1721 - segnet_out_accuracy: 0.7662 - bin_class_out_accuracy: 0.9158 - bbox_out_accuracy: 0.2799 - val_loss: 1.4129 - val_segnet_out_loss: 0.2770 - val_bin_class_out_loss: 0.0352 - val_bbox_out_loss: 110.0770 - val_segnet_out_accuracy: 0.9118 - val_bin_class_out_accuracy: 0.9905 - val_bbox_out_accuracy: 0.3003\n",
      "Epoch 2/3\n",
      "184/184 [==============================] - 102s 554ms/step - loss: 1.3860 - segnet_out_loss: 0.2486 - bin_class_out_loss: 0.0504 - bbox_out_loss: 108.7005 - segnet_out_accuracy: 0.9111 - bin_class_out_accuracy: 0.9898 - bbox_out_accuracy: 0.3791 - val_loss: 1.2897 - val_segnet_out_loss: 0.1930 - val_bin_class_out_loss: 0.0281 - val_bbox_out_loss: 106.8700 - val_segnet_out_accuracy: 0.9356 - val_bin_class_out_accuracy: 0.9932 - val_bbox_out_accuracy: 0.4076\n",
      "Epoch 3/3\n",
      "184/184 [==============================] - 102s 554ms/step - loss: 1.2700 - segnet_out_loss: 0.1889 - bin_class_out_loss: 0.0249 - bbox_out_loss: 105.6200 - segnet_out_accuracy: 0.9368 - bin_class_out_accuracy: 0.9952 - bbox_out_accuracy: 0.4688 - val_loss: 1.2179 - val_segnet_out_loss: 0.1595 - val_bin_class_out_loss: 0.0314 - val_bbox_out_loss: 102.7071 - val_segnet_out_accuracy: 0.9446 - val_bin_class_out_accuracy: 0.9905 - val_bbox_out_accuracy: 0.4701\n",
      "-------------------- start cross val 2/3 --------------------\n",
      "Epoch 1/3\n",
      "184/184 [==============================] - 112s 563ms/step - loss: 1.8296 - segnet_out_loss: 0.4780 - bin_class_out_loss: 0.2412 - bbox_out_loss: 111.0430 - segnet_out_accuracy: 0.7763 - bin_class_out_accuracy: 0.9103 - bbox_out_accuracy: 0.2887 - val_loss: 1.4270 - val_segnet_out_loss: 0.2672 - val_bin_class_out_loss: 0.0404 - val_bbox_out_loss: 111.9380 - val_segnet_out_accuracy: 0.9118 - val_bin_class_out_accuracy: 0.9878 - val_bbox_out_accuracy: 0.4117\n",
      "Epoch 2/3\n",
      " 77/184 [===========>..................] - ETA: 39s - loss: 1.4246 - segnet_out_loss: 0.2634 - bin_class_out_loss: 0.0551 - bbox_out_loss: 110.6022 - segnet_out_accuracy: 0.9059 - bin_class_out_accuracy: 0.9951 - bbox_out_accuracy: 0.3685"
     ]
    }
   ],
   "source": [
    "##### Change this to modify the folds #####\n",
    "CVfolds = 3\n",
    "###########################################\n",
    "val_acc = []\n",
    "num_train_cv = num_train * (CVfolds-1)/CVfolds\n",
    "num_val_cv = num_train * 1/CVfolds\n",
    "\n",
    "for cv_iter in range(CVfolds):\n",
    "      # CrossVal: 0 = no CV, 1 = training set, 2 = val set\n",
    "      loader1 = DataLoader(batch_size=batch_size, batch_size_val=batch_size_val, CrossVal=1, CV_iteration=cv_iter, fold=CVfolds)\n",
    "      loader2 = DataLoader(batch_size=batch_size, batch_size_val=batch_size_val, CrossVal=2, CV_iteration=cv_iter, fold=CVfolds)\n",
    "\n",
    "      # Train set\n",
    "      img_ds = loader1.get_image_ds().repeat()\n",
    "      masks_ds = loader1.get_mask_ds().repeat()\n",
    "      label_ds = loader1.get_binary_ds().repeat()\n",
    "      bbox_ds = loader1.get_bboxes_ds().repeat()\n",
    "\n",
    "      # Validation set\n",
    "      img_ds_val = loader2.get_image_ds().repeat()\n",
    "      masks_ds_val = loader2.get_mask_ds().repeat()\n",
    "      label_ds_val = loader2.get_binary_ds().repeat()\n",
    "      bbox_ds_val = loader2.get_bboxes_ds().repeat()\n",
    "      \n",
    "      model = build_model(img_height, img_width, channels)\n",
    "\n",
    "      model.compile(optimizer=keras.optimizers.Adam(1e-4),\n",
    "                  loss={'segnet_out' : tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "                        'bin_class_out' : tf.keras.losses.BinaryCrossentropy(),\n",
    "                        'bbox_out' : tf.keras.losses.MeanAbsoluteError()},\n",
    "                  loss_weights=[1,1,1/100], # Scale MAE to BC range\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "      print(f\"-------------------- start cross val {cv_iter+1}/{CVfolds} --------------------\")\n",
    "\n",
    "      history = model.fit(generator_img(img_ds, masks_ds, label_ds, bbox_ds), \n",
    "                        validation_data=generator_img_val(img_ds_val, masks_ds_val, label_ds_val, bbox_ds), \n",
    "                        epochs=3, \n",
    "                        steps_per_epoch=num_train_cv//batch_size, \n",
    "                        validation_steps=num_val_cv//batch_size_val)\n",
    "\n",
    "      # save the final val_acc \n",
    "      val_acc.append([history.history['val_segnet_out_accuracy'][-1], \n",
    "                              history.history['val_bin_class_out_accuracy'][-1],\n",
    "                              history.history['val_bbox_out_accuracy'][-1]])\n",
    "\n",
    "      # print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tsegnet \tbinary \tbbox\n",
      "CV 1 \t0.898 \t0.001 \t0.383\n",
      "CV 2 \t0.902 \t0.505 \t0.576\n",
      "CV 3 \t0.936 \t0.625 \t0.688\n",
      "-----------------------------\n",
      "Avg  \t0.912 \t0.377 \t0.549\n"
     ]
    }
   ],
   "source": [
    "# Print out the results to see offline\n",
    "print(\"\\tsegnet \\tbinary \\tbbox\")\n",
    "for i in range(3):\n",
    "    print(f\"CV {i+1} \\t{np.round(val_acc[i][0], 3)} \\t{np.round(val_acc[i][1], 3)} \\t{np.round(val_acc[i][2], 3)}\")\n",
    "\n",
    "print(\"-----------------------------\")\n",
    "avg = np.round(np.mean(val_acc, axis=0), 3)\n",
    "print(f\"Avg  \\t{avg[0]} \\t{avg[1]} \\t{avg[2]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(8,6))\n",
    "#ax.plot(list(range(10)), history.history['segnet_out_accuracy'], 'r-', label='Segmentation - Training Accuracy')\n",
    "ax.plot(list(range(10)), history.history['val_segnet_out_accuracy'], 'r--', label='Segmentation - Validation Accuracy')\n",
    "#ax.plot(list(range(10)), history.history['bin_class_out_accuracy'], 'c-', label='Classification - Training Accuracy')\n",
    "ax.plot(list(range(10)), history.history['val_bin_class_out_accuracy'], 'c--', label='Classification - Validation Accuracy')\n",
    "ax2 = ax.twinx()\n",
    "#ax.plot(list(range(10)), history.history['bbox_out_accuracy'], 'm-', label='Bounding Box - Training Accuracy')\n",
    "ax.plot(list(range(10)), history.history['val_bbox_out_accuracy'], 'm--', label='Bounding Box - Validation Accuracy')\n",
    "ax.legend()\n",
    "ax.set_xlabel('Epochs')\n",
    "ax.set_ylabel('Segmentation/Classification Accuracy')\n",
    "ax2.set_ylabel('Bounding Box Accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('EffishingNetN')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test on test-set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.load_model('EffishingNetN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load test-set\n",
    "img_ds_test = loader.get_image_ds(test_mode=True)\n",
    "masks_ds_test = loader.get_mask_ds(test_mode=True)\n",
    "label_ds_test = loader.get_binary_ds(test_mode=True)\n",
    "bbox_ds_test = loader.get_bboxes_ds(test_mode=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict on test-set\n",
    "seg_pred, bin_pred, bbox_pred = model.predict(img_ds_test, batch_size=10)\n",
    "seg_pred = tf.where(seg_pred >= 0, 1, 0) # Convert to {0,1} binary classes\n",
    "bin_pred = np.round(bin_pred) # Round confidence score\n",
    "\n",
    "bin_acc = np.sum(bin_pred == label_ds_test)/label_ds_test.shape[0]\n",
    "seg_acc = np.sum(seg_pred == masks_ds_test)/(masks_ds_test.shape[0]*(img_height*img_width))\n",
    "iou = np.mean(tools.calculate_iou(bbox_ds_test, bbox_pred))\n",
    "print(f'Binary Acc: {round(bin_acc*100, 3)}%,   Seg Acc: {round(seg_acc*100, 3)}%,    BBox IOU: {round(iou*100, 3)}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_seg_pred(img: np.array, mask_truth: np.array, mask_pred: np.array, bbox_truth: np.array, bbox_pred: np.array):\n",
    "    ''' Show segmentation prediction with bounding box pred '''\n",
    "    fig, (ax1, ax2, ax3, ax4) = plt.subplots(1, 4, figsize=(12,12))\n",
    "    seg_max = tf.where(mask_pred > 0, 1, 0)\n",
    "    box_img_truth = tf.image.draw_bounding_boxes(tf.cast(tf.expand_dims(img, 0), tf.float32), tools.fix_bbox(bbox_truth).reshape([1,1,4])/256, np.array([[255, 0, 0]]))\n",
    "    box_img = tf.image.draw_bounding_boxes(tf.cast(tf.expand_dims(img, 0), tf.float32), tools.fix_bbox(bbox_pred).reshape([1,1,4])/256, np.array([[0, 255, 0]]))\n",
    "    \n",
    "    ax1.imshow(tf.keras.utils.array_to_img(tf.squeeze(box_img_truth)))\n",
    "    ax2.imshow(tf.keras.utils.array_to_img(tf.squeeze(box_img)))\n",
    "    ax3.imshow(tf.keras.utils.array_to_img(mask_truth))\n",
    "    ax4.imshow(tf.keras.utils.array_to_img(seg_max[0]))\n",
    "    ax1.set_title('Truth')\n",
    "    ax2.set_title('Prediction')\n",
    "    ax3.set_title('Truth')\n",
    "    ax4.set_title('Prediction')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualise predictions\n",
    "idx = list(range(img_ds_test.shape[0]))\n",
    "random.shuffle(idx)\n",
    "for i in range(3):\n",
    "    show_seg_pred(img_ds_test[idx[i]], masks_ds_test[idx[i]], seg_pred[idx[i]][tf.newaxis, ...], bbox_ds_test[idx[i]], bbox_pred[idx[i]])"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "13872f827bf2face4951d508a343680c0c465a86f8c76a51d647b255bdadb53b"
  },
  "kernelspec": {
   "display_name": "Python 3.9.9 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
