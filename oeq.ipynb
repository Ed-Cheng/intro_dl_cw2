{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "uGSAKto8mpWF"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import backend as K\n",
        "import numpy as np\n",
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from utils.loader import DataLoader\n",
        "from models.effnet_encoder import EffnetEncoder\n",
        "from models.mtl_framework import MTLFramework\n",
        "from utils import tools, config"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "ruV3TgbcmpWH"
      },
      "outputs": [],
      "source": [
        "# Set configs\n",
        "batch_size = 32\n",
        "batch_size_val = 32\n",
        "num_train, num_val, num_test = config.config['num_train'], config.config['num_val'], config.config['num_test']\n",
        "img_height, img_width, channels = config.config['input_shape']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "HydKJtTkmpWI"
      },
      "outputs": [],
      "source": [
        "# Load our data pipeline\n",
        "loader = DataLoader(batch_size=batch_size, batch_size_val=batch_size_val)\n",
        "\n",
        "# Train set\n",
        "img_ds = loader.get_image_ds().repeat()\n",
        "masks_ds = loader.get_mask_ds().repeat()\n",
        "label_ds = loader.get_binary_ds().repeat()\n",
        "bbox_ds = loader.get_bboxes_ds().repeat()\n",
        "\n",
        "# Validation set\n",
        "img_ds_val = loader.get_image_ds(val=True).repeat()\n",
        "masks_ds_val = loader.get_mask_ds(val=True).repeat()\n",
        "label_ds_val = loader.get_binary_ds(val=True).repeat()\n",
        "bbox_ds_val = loader.get_bboxes_ds(val=True).repeat()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QjqZoxm8mpWJ"
      },
      "source": [
        "Build our MTL"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XSNZRKtompWK"
      },
      "outputs": [],
      "source": [
        "### CLEARS OLD MODELS IN CACHE\n",
        "tf.keras.backend.clear_session()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "AoEwJ3WYmpWK"
      },
      "outputs": [],
      "source": [
        "# Get encoder with attention unit\n",
        "base_model_name = 'B0'\n",
        "encoder = EffnetEncoder(base_model_name, (img_height, img_width, channels)).build_encoder_with_attention(trainable=True) # EfficientNet with attention"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B3AbjZJ7mpWL"
      },
      "outputs": [],
      "source": [
        "encoder.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F2rNez0jmpWM"
      },
      "outputs": [],
      "source": [
        "# Use our MTL framework to custom build a model\n",
        "mtl_builder = MTLFramework(encoder, (img_height, img_width, channels)) # We pass the new attention based EfficientNet encoder\n",
        "mtl_builder.add_segmentation_head()\n",
        "mtl_builder.add_binary_classification_head(base_model_name, trainable=True)\n",
        "mtl_builder.add_bbox_classification_head(base_model_name, trainable=True)\n",
        "model = mtl_builder.build_mtl_model()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "id": "v6WI0RblDz2q"
      },
      "outputs": [],
      "source": [
        "model.trainable = True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OBzoQg5bmpWN"
      },
      "outputs": [],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dwtwMwEVmpWN"
      },
      "source": [
        "Train model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "DjeR0CJimpWO"
      },
      "outputs": [],
      "source": [
        "def generator_img():\n",
        "    ''' Merges together datasets into a unified generator to pass for training '''\n",
        "    a = img_ds.as_numpy_iterator()\n",
        "    b = masks_ds.as_numpy_iterator()\n",
        "    c = label_ds.as_numpy_iterator()\n",
        "    d = bbox_ds.as_numpy_iterator()\n",
        "    \n",
        "    while True:\n",
        "        X = a.next()\n",
        "        Y1 = b.next()\n",
        "        Y2 = c.next()\n",
        "        Y3 = d.next()\n",
        "        \n",
        "        # Regularisation and shuffling\n",
        "        X, Y1, Y2, Y3 = tools.get_randomised_data([X, Y1, Y2, Y3])\n",
        "        X, Y1, Y3 = tools.data_augmentation(X, Y1, Y3) # Fix augmentation\n",
        "        \n",
        "        yield X, (Y1, Y2, Y3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "tBc4LjuZmpWO"
      },
      "outputs": [],
      "source": [
        "def generator_img_val():\n",
        "    ''' Merges together datasets into a unified generator to pass for training '''\n",
        "    a = img_ds_val.as_numpy_iterator()\n",
        "    b = masks_ds_val.as_numpy_iterator()\n",
        "    c = label_ds_val.as_numpy_iterator()\n",
        "    d = bbox_ds.as_numpy_iterator()\n",
        "    \n",
        "    while True:\n",
        "        X = a.next()\n",
        "        Y1 = b.next()\n",
        "        Y2 = c.next()\n",
        "        Y3 = d.next()\n",
        "        \n",
        "        yield X, (Y1, Y2, Y3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "id": "JL3CU6ksmpWQ"
      },
      "outputs": [],
      "source": [
        "# Initial training\n",
        "model.compile(optimizer=keras.optimizers.Adam(),\n",
        "              loss={'segnet_out' : tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
        "                    'bin_class_out' : tf.keras.losses.BinaryCrossentropy(),\n",
        "                    'bbox_out' : tf.keras.losses.MeanAbsoluteError()},\n",
        "              loss_weights=[1,1,1/100], # Scale MAE to BC range\n",
        "              metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fDeJ3CopmpWR",
        "outputId": "425b2c1e-109e-4dc3-c222-51f7a8b665dd"
      },
      "outputs": [],
      "source": [
        "history = model.fit(generator_img(), validation_data=generator_img_val(), epochs=15, steps_per_epoch=num_train//batch_size, validation_steps=num_val//batch_size_val)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JL3CU6ksmpWQ"
      },
      "outputs": [],
      "source": [
        "# Fine-tuning at lower LR\n",
        "model.compile(optimizer=keras.optimizers.Adam(1e-4),\n",
        "              loss={'segnet_out' : tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
        "                    'bin_class_out' : tf.keras.losses.BinaryCrossentropy(),\n",
        "                    'bbox_out' : tf.keras.losses.MeanAbsoluteError()},\n",
        "              loss_weights=[1,1,1/100], # Scale MAE to BC range\n",
        "              metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fDeJ3CopmpWR",
        "outputId": "425b2c1e-109e-4dc3-c222-51f7a8b665dd"
      },
      "outputs": [],
      "source": [
        "history = model.fit(generator_img(), validation_data=generator_img_val(), epochs=10, steps_per_epoch=num_train//batch_size, validation_steps=num_val//batch_size_val)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XcwOXhDrmpWS",
        "outputId": "049d255f-7ed5-4aea-adcb-7c68699ea171"
      },
      "outputs": [],
      "source": [
        "model.save('model_weights/EffishingNetAtt_Eff')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t6poGhw4mpWS"
      },
      "source": [
        "## Test on test-set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "yGr3aObxmpWT"
      },
      "outputs": [],
      "source": [
        "model = tf.keras.models.load_model('model_weights/EffishingNetAtt_Eff')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "AhJzZ9n6mpWT"
      },
      "outputs": [],
      "source": [
        "# Load test-set\n",
        "img_ds_test = loader.get_image_ds(test_mode=True)\n",
        "masks_ds_test = loader.get_mask_ds(test_mode=True)\n",
        "label_ds_test = loader.get_binary_ds(test_mode=True)\n",
        "bbox_ds_test = loader.get_bboxes_ds(test_mode=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZO8g8G_cmpWU",
        "outputId": "8509193d-5320-4b63-ca0f-f09d0c78e6cc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Binary Acc: 99.322%,   Seg Acc: 95.772%,    BBox IOU: 79.134%\n"
          ]
        }
      ],
      "source": [
        "# Predict on test-set\n",
        "seg_pred, bin_pred, bbox_pred = model.predict(img_ds_test, batch_size=10)\n",
        "seg_pred = tf.where(seg_pred >= 0, 1, 0) # Convert to {0,1} binary classes\n",
        "bin_pred = np.round(bin_pred) # Round confidence score\n",
        "\n",
        "bin_acc = np.sum(bin_pred == label_ds_test)/label_ds_test.shape[0]\n",
        "seg_acc = np.sum(seg_pred == masks_ds_test)/(masks_ds_test.shape[0]*(img_height*img_width))\n",
        "iou = np.mean(tools.calculate_iou(bbox_ds_test, bbox_pred))\n",
        "print(f'Binary Acc: {round(bin_acc*100, 3)}%,   Seg Acc: {round(seg_acc*100, 3)}%,    BBox IOU: {round(iou*100, 3)}%')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f9jtqs5yooSj",
        "outputId": "7cb8870d-3085-49fe-8f12-6d139e780550"
      },
      "outputs": [],
      "source": [
        "# Get precision\n",
        "m = tf.keras.metrics.Precision()\n",
        "m.update_state(seg_pred, masks_ds_test)\n",
        "print(f'Precision of network: {m.result().numpy()}')\n",
        "\n",
        "# Get recall\n",
        "m = tf.keras.metrics.Recall()\n",
        "m.update_state(seg_pred, masks_ds_test)\n",
        "print(f'Recall of network: {m.result().numpy()}')\n",
        "\n",
        "# Get Dice metric\n",
        "m = tf.keras.metrics.MeanIoU(num_classes=2)\n",
        "m.update_state(seg_pred, masks_ds_test)\n",
        "print(f'Dice score of network: {m.result().numpy()}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Get feature maps"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "input_img = next(img_ds.as_numpy_iterator()) # Get test image\n",
        "\n",
        "# Build new model with intermediate layer as output\n",
        "XX = model.input \n",
        "YY = model.layers[-12].output\n",
        "new_model = tf.keras.Model(XX, YY)\n",
        "\n",
        "Xresult = new_model.predict(input_img) # Get feature map\n",
        "\n",
        "# fig, ax = plt.subplots(5, 10, figsize=(15, 7)) # REMOVE?\n",
        "\n",
        "# for j in range(5):\n",
        "#     for i in range(10):\n",
        "#         ax[j][i].imshow(Xresult[0, :, :, j*20 + i + 10])\n",
        "#         ax[j][i].axis('off')"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "name": "oeq2.ipynb",
      "provenance": []
    },
    "interpreter": {
      "hash": "13872f827bf2face4951d508a343680c0c465a86f8c76a51d647b255bdadb53b"
    },
    "kernelspec": {
      "display_name": "Python 3.9.9 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.9"
    },
    "orig_nbformat": 4
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
